{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec0acbc",
   "metadata": {},
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47aba6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8c023c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "x_train = train.iloc[:,1:-1] # features of training data, excluding id\n",
    "y_train = train.iloc[:,-1] # label of training data\n",
    "\n",
    "x_test = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ad67f",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c396455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1        2       3        4       5       6        7     8   \\\n",
      "0   3556.0  2489.0   265.19   77.53   176.55    0.00    4.20   307.91  52.0   \n",
      "1   1906.0   134.0  1442.61  551.90   876.07  112.10  168.15  1735.48  20.0   \n",
      "2   1586.0    71.0  1332.74  684.20   655.26  244.95  216.52  1820.04  28.0   \n",
      "3    683.0    94.0   419.23  255.80   162.17   72.05   44.68   538.22  55.0   \n",
      "4   1032.0    71.0  1102.72  480.27   625.30  188.78  130.77  1427.97  28.0   \n",
      "..     ...     ...      ...     ...      ...     ...     ...      ...   ...   \n",
      "82   626.0    68.0  1771.57  666.99  1117.48  360.21  118.84  2306.82  42.0   \n",
      "83  1237.0    71.0  1348.53  428.09   924.69  120.02   48.67  1524.78  56.0   \n",
      "84   634.0  1002.0  1300.00  558.00   724.00   67.00  105.00  1484.26  34.0   \n",
      "85   112.0   884.0   942.83  378.49   567.06  116.77   31.81  1104.59  33.0   \n",
      "86   195.0   213.0   724.00  364.00   361.00   18.00  155.00   897.00  19.0   \n",
      "\n",
      "     9       10  \n",
      "0   0.0  7515.0  \n",
      "1   1.0  1756.0  \n",
      "2   1.0  1311.0  \n",
      "3   1.0  1443.0  \n",
      "4   1.0  1542.0  \n",
      "..  ...     ...  \n",
      "82  1.0  1521.0  \n",
      "83  0.0  1345.0  \n",
      "84  0.0  2926.0  \n",
      "85  1.0  2352.0  \n",
      "86  1.0  2445.0  \n",
      "\n",
      "[87 rows x 11 columns]\n",
      "        0       1        2        3        4       5       6        7     8   \\\n",
      "0   2843.0   156.0  1358.52   730.78   637.85  127.06   94.82  1588.62  45.0   \n",
      "1    437.0   137.0   509.43   268.05   243.07  390.86   98.24  1002.76  51.0   \n",
      "2    826.0    82.0  1232.22   493.42   744.08  516.28  320.15  2200.58  32.0   \n",
      "3    861.0    50.0  1512.86   925.51   590.07  380.25   25.80  1929.10  50.0   \n",
      "4   1160.0   157.0   890.42   403.91   489.53  266.92   87.63  1251.52  43.0   \n",
      "5    867.0    85.0  1662.11   865.50   804.14  220.68   92.58  2063.11  44.0   \n",
      "6   1330.0   114.0  1307.95   710.86   607.96  271.01  214.49  1855.05  31.0   \n",
      "7    494.0    48.0  1522.39   618.19   911.49  338.85  104.45  2013.05  36.0   \n",
      "8   2119.0    73.0  1219.66   732.14   468.48   71.54   83.08  1378.32  45.0   \n",
      "9   2052.0    39.0  1223.65   642.55   565.39  323.67  153.64  1711.88  36.0   \n",
      "10  4195.0   134.0  1513.79   776.94   752.60  110.28  142.50  1780.88  45.0   \n",
      "11   819.0  1000.0   794.33   391.72   407.35  312.61  113.20  1236.72  45.0   \n",
      "12   685.0    60.0   470.04   114.98   321.32  174.86   31.49   679.19  62.0   \n",
      "13  1330.0   114.0  1307.95   710.86   607.96  271.01  214.49  1855.05  31.0   \n",
      "14    82.0    30.0   693.25   426.73   272.51  956.78  120.53  1825.96  27.0   \n",
      "15   781.0    43.0  1537.36   922.55   620.05  142.08   66.13  1771.11  36.0   \n",
      "16  2140.0   125.0  2771.20  1738.55  1006.96  367.85  203.45  3355.86  27.0   \n",
      "17  1005.0    93.0  1061.65   379.12   683.06   99.71   76.25  1241.34  33.0   \n",
      "18  1202.0    39.0   716.76   272.92   447.73   89.55  121.08   931.68  54.0   \n",
      "19   660.0    43.0   886.57   225.68   620.75  196.49  106.33  1202.41  54.0   \n",
      "20  1289.0   272.0   583.00   206.00   373.00   18.00   59.00   660.00  29.0   \n",
      "21  2238.0   539.0   850.05   438.98   352.71  235.14   91.35  1182.46  44.0   \n",
      "22   127.0    81.0   435.00   259.00   166.00   57.00   60.00   558.00  54.0   \n",
      "23   880.0    38.0   773.79   369.33   412.49  412.99   55.20  1257.03  34.0   \n",
      "24  3232.0    72.0  2017.32   850.72  1176.28  440.86  501.91  2964.93  15.0   \n",
      "25   902.0  1141.0   258.01   168.63    99.18   45.46    8.83   314.25  50.0   \n",
      "26   922.0   167.0  2122.97  1443.00   689.42   87.11  122.22  2369.43  36.0   \n",
      "27  1520.0    67.0   829.56   293.00   511.00  403.13  144.62  1378.89  47.0   \n",
      "28   313.0   382.0   632.45   289.46   346.06  138.08   44.32   816.55  53.0   \n",
      "29  1240.0    59.0  1071.75   513.58   443.52  110.01  125.65  1311.46  50.0   \n",
      "30  1208.0   460.0  1492.00   422.00  1048.00   56.00   23.00  1571.00  55.0   \n",
      "31   601.0  1080.0   306.71   210.30    98.45   57.50   71.73   436.83  39.0   \n",
      "32  1814.0   143.0   627.33   268.55   376.05  155.43   46.63   833.27  52.0   \n",
      "33   232.0   615.0   352.11   221.62   131.79   74.31  170.87   601.47  41.0   \n",
      "34  1078.0   238.0   755.15   345.75   413.33  779.42   76.76  1648.73  52.0   \n",
      "35  1085.0    24.0  1970.56  1296.13   601.93  388.11  186.00  2549.06  34.0   \n",
      "36  1851.0    95.0  1498.79   983.18   525.76  147.51   50.75  1701.79  45.0   \n",
      "37   402.0   378.0   544.54   227.96   327.85  283.54   36.11   898.00  39.0   \n",
      "38   909.0   574.0   326.77   244.91    80.39   42.97   16.01   386.90  47.0   \n",
      "39  1296.0   148.0  1328.00   642.00   670.00  666.11  266.87  2267.31  51.0   \n",
      "40  1784.0   474.0   337.75   133.11   204.64   25.50   16.00   379.25  42.0   \n",
      "41   676.0    64.0   622.25   345.00   221.00   50.60   56.04   731.13  29.0   \n",
      "42   629.0    76.0   427.06   240.16   138.57   83.83    2.96   525.20  42.0   \n",
      "43   721.0   117.0   983.00   449.00   539.00  141.00   76.00  1200.00  37.0   \n",
      "44  1733.0   134.0  1443.62   770.62   613.22   85.40  227.47  1760.90  42.0   \n",
      "45  1546.0   184.0   832.08   621.01   210.58  141.36   63.86  1043.63  51.0   \n",
      "46   838.0   226.0  1025.32   728.71   296.61  187.36  135.49  1358.55  38.0   \n",
      "47   740.0   187.0   530.77   154.69   377.34   40.07   45.14   618.76  31.0   \n",
      "48   494.0    61.0  1568.54   937.00   601.00  246.48  165.92  1983.61  38.0   \n",
      "49  1700.0    71.0  1106.54   503.71   547.54  363.45  176.67  1650.03  48.0   \n",
      "50  1175.0    60.0   847.11   362.52   486.42  512.66  116.57  1486.10  47.0   \n",
      "51  1956.0   152.0  1786.48   783.82   952.42  194.75  198.19  2188.36  40.0   \n",
      "52  1122.0    66.0  1955.03  1080.16   879.77  111.60  100.20  2201.04  30.0   \n",
      "53  2492.0    60.0  2278.56   937.47  1225.68  252.10  304.97  2864.00  21.0   \n",
      "54   708.0   248.0  1304.86   433.61   789.19  257.43  122.28  1691.81  37.0   \n",
      "55   560.0    74.0   727.01   227.25   502.48  159.80  106.38  1011.29  54.0   \n",
      "56  1948.0   264.0  1836.00   838.96   819.69  184.56  105.53  1943.45  35.0   \n",
      "57  1010.0    90.0  1061.65   379.12   683.06   99.71   76.25  1241.34  34.0   \n",
      "58   674.0   380.0   393.49   256.02   137.27   17.72   63.81   479.55  40.0   \n",
      "\n",
      "     9       10  \n",
      "0   1.0  3256.0  \n",
      "1   1.0   491.0  \n",
      "2   0.0  1381.0  \n",
      "3   0.0  1377.0  \n",
      "4   0.0  1844.0  \n",
      "5   1.0   986.0  \n",
      "6   0.0  2077.0  \n",
      "7   1.0  1409.0  \n",
      "8   1.0  2403.0  \n",
      "9   0.0  1701.0  \n",
      "10  1.0  3160.0  \n",
      "11  0.0  4086.0  \n",
      "12  0.0   737.0  \n",
      "13  0.0  2077.0  \n",
      "14  0.0   371.0  \n",
      "15  0.0   930.0  \n",
      "16  1.0  2183.0  \n",
      "17  0.0  1269.0  \n",
      "18  1.0   643.0  \n",
      "19  0.0   814.0  \n",
      "20  0.0  2581.0  \n",
      "21  0.0  4361.0  \n",
      "22  1.0   856.0  \n",
      "23  0.0   800.0  \n",
      "24  1.0  1517.0  \n",
      "25  1.0  3244.0  \n",
      "26  0.0  1995.0  \n",
      "27  1.0  1700.0  \n",
      "28  0.0  2656.0  \n",
      "29  1.0  1203.0  \n",
      "30  1.0  1761.0  \n",
      "31  0.0  4413.0  \n",
      "32  0.0  1298.0  \n",
      "33  0.0  1040.0  \n",
      "34  0.0  2506.0  \n",
      "35  0.0   639.0  \n",
      "36  1.0  2347.0  \n",
      "37  0.0  1849.0  \n",
      "38  0.0  3969.0  \n",
      "39  0.0  2061.0  \n",
      "40  0.0  6788.0  \n",
      "41  0.0  1660.0  \n",
      "42  0.0  1391.0  \n",
      "43  0.0  2771.0  \n",
      "44  1.0  1501.0  \n",
      "45  0.0  2281.0  \n",
      "46  1.0  1662.0  \n",
      "47  0.0  2617.0  \n",
      "48  0.0  1923.0  \n",
      "49  0.0  1617.0  \n",
      "50  0.0  2013.0  \n",
      "51  1.0  2251.0  \n",
      "52  0.0  1468.0  \n",
      "53  1.0   924.0  \n",
      "54  1.0  1669.0  \n",
      "55  0.0  1235.0  \n",
      "56  1.0  2126.0  \n",
      "57  0.0  1319.0  \n",
      "58  0.0  3095.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(x_train)\n",
    "x_train = imputer.transform(x_train)\n",
    "x_train = pd.DataFrame(x_train)\n",
    "print(x_train)\n",
    "\n",
    "imputer = imputer.fit(x_test)\n",
    "x_test = imputer.transform(x_test)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "074383a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 11) (18, 11) (69,) (18,) (59, 11)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# split the data for validation \n",
    "x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, test_size=0.2, train_size=0.8, random_state=2)\n",
    "print(x_train_new.shape,x_val.shape,y_train_new.shape,y_val.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12710db",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed54f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random_state: 32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def val(i):\n",
    "    clf = RandomForestClassifier(n_estimators=50, max_depth=8, random_state=i)\n",
    "    clf.fit(x_train_new, y_train_new)\n",
    "    y_pred = clf.predict(x_val)\n",
    "    return accuracy_score(y_val,y_pred)\n",
    "\n",
    "for i in range(1,100): # find the random_state with higher accuracy\n",
    "    acc = val(i)\n",
    "    if acc == 1.0:\n",
    "        print('The best random_state:', i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6781c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, max_depth=7, random_state=32)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_train)\n",
    "print('Training Accuracy:', accuracy_score(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64675dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "results = y_pred.tolist()\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['id'] = test['id']\n",
    "res['label'] = results\n",
    "res.to_csv('submission.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
